<!DOCTYPE HTML>
<html>
<head>
  <title>Anjalie Field, CMU</title>
	<meta name="google-site-verification" content="_icP2W3B6y_gFG92Dh-caUWIh_sEnE4tPu8pghzaH2w" />
  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.2.1/jquery.min.js"></script>
  <link href="https://fonts.googleapis.com/css?family=Julius+Sans+One" rel="stylesheet">
  <link rel="stylesheet" href="css/style.css">
	<script src="https://ajax.googleapis.com/ajax/libs/jquery/3.2.1/jquery.min.js"></script>
</head>

<body>
<!--  IF YOU CHANGE THIS ALSO CHANGE IT IN INDEX and STATEMENTS -->
  <div class="banner">
    <div id="header">
      <div id="name">
        Anjalie Field
      </div>
      <div id="navigator">
        <div class="nav_cell"><a class="nav" href="index.html" id="about">About</a></div>
        <div class="nav_cell"><a class="nav" href="docs/Resume.pdf" id="resume">C.V.</a></div>
        <div class="nav_cell"><a class="nav" href="statements.html" id="statements">Research Statements</a></div>
      </div>
    </div>
  </div>

  <div id="main">
    <div class="content">
      <div class="introduction" id="main_box">
        <div class="subtitle">Research Areas</div>
        My primary field of research is natural language processing, and some of my work could be considered data science.
        Within this space, I focus on social-oriented topics that broadly fall under three categories:
        <br>

        <br>
        <br>
        <div class="application_title">Computational Social Science</div>
        Can we use automated text processing tools to help us identify and understand social phenomena? Research questions in this space might include: what
        motivates successful social movements? What are large-scale propaganda strategies and are they effective? How do conceptualizations of "stereotypes" and "bias"
        differ across cultures and domains? This line of work sometimes involves developing new technology that facilitates open-ended text analysis and
        sometimes involves actually conducting those analyses, often in partnership with social scientists. The long-term impact goals of these projects often focus
        on informing policy decisions. Some papers in this space include:

        <ul>
        <li><div class="publication"> Chan Young Park*, Julia Mendelsohn*, Anjalie Field*, and Yulia Tsvetkov. "Challenges in Opinion Manipulation Detection: An Examination of Wartime Russian Media" Findings of EMNLP (2022).  (<a class="link" href="https://arxiv.org/abs/2205.12382" target="_blank">text</a>) </div>
        </li>
        <li><div class="publication">
            Anjalie Field*, Chan Young Park*, Antonio Theophilo*, Jamelle Watson-Daniels, and Yulia Tsvetkov. "An Analysis of Emotions and the Prominence of Positivity in #BlackLivesMatter Tweets" PNAS (2022).  (<a class="link" href="https://www.pnas.org/doi/abs/10.1073/pnas.2205767119" target="_blank">text</a>, <a class="link" href="https://www.pnas.org/doi/abs/10.1073/pnas.2205767119" target="_blank">code</a>) </div>
        </li>
        <li><div class="publication">
            Anjalie Field, Gayatri Bhat, and Yulia Tsvetkov. "Contextual Affective Analysis: A Case Study of People Portrayals in Online #MeToo Stories" ICWSM (2019). (<a class="link" href="https://arxiv.org/abs/1904.04164" target="_blank">text</a>, <a class="link" href="https://github.com/anjalief/metoo_icwsm2019">code</a>)
        </div></li>
      
        <li><div class="publication">
            Anjalie Field, Doron Kliger, Shuly Wintner, Jennifer Pan, Dan Jurafsky, and Yulia Tsvetkov. "Framing and Agenda-setting in Russian News: a Computational Analysis of Intricate Political Strategies." EMNLP (2018). (<a class="link" href="https://arxiv.org/pdf/1808.09386.pdf" target="_blank">text</a>, <a class="link" href="https://github.com/anjalief/framing_agenda_setting" target="_blank">code</a>)
        </div></li>
        </ul>

        <br>
        <br>
        <div class="application_title">NLP for Social Good</div>
        This line of work focuses on developing NLP models that have the potential to address a broad range of societal issues. Some of the application domains I currently have interests in include propaganda and misinformation, stereotypes and bias, and child welfare.
        The long-term impact goals of these projects focus on deployable technology. Some relevant papers include:


        <ul>
        <li><div class="publication"> Anjalie Field, Chan Young Park, Kevin Z. Lin, and Yulia Tsvetkov. "Controlled Analyses of Social Biases in Wikipedia Bios" WebConf (2022).  (<a class="link" href="https://arxiv.org/abs/2101.00078" target="_blank">text</a>, <a class="link" href="https://github.com/anjalief/wikipedia_bias_public" target="_blank">code</a>) </div></li>
        
        <li><div class="publication"> Nupoor Gandhi, Anjalie Field, and Yulia Tsvetkov. "Improving Span Representation for Domain-adapted Coreference Resolution" Workshop on Computational Models of Reference, Anaphora and Coreference at EMNLP (2021). (<a class="link" href="https://arxiv.org/pdf/2109.09811.pdf" target="_blank">text</a>) </div></li>
      
        <li><div class="publication"> Anjalie Field and Yulia Tsvetkov. "Unsupervised Discovery of Implicit Gender Bias" EMNLP (2020). (<a class="link" href="https://aclanthology.org/2020.emnlp-main.44/" target="_blank">text</a>, <a href="https://github.com/anjalief/unsupervised_gender_bias" target="_blank">code</a>) </div></li>
        </ul>

        <br>
        <br>
        <div class="application_title">Ethics in NLP</div>
        We cannot seek to develop models for "social good" and understand societal issues without self-reflecting on potential harms and issues in our own field. This line of research focuses
        on measuring and mitigating potential harms in NLP pipelines and their development. The long-term impact goals of these projects focus on shaping policy, specifically around NLP use and development.
        Sample papers include:

        <ul>
            <li><div class="publication"> Inna Wanyin Lin*, Lucille Njoo*, Anjalie Field, Ashish Sharma, Katharina Reinecke, Tim Althoff, and Yulia Tsvetkov "Gendered Mental Health Stigma in Masked Language Models" EMNLP (2022). </div></li>
        <li><div class="publication">Anjalie Field, Su Lin Blodgett, Zeerak Waseem, and Yulia Tsvetkov. "A Survey of Race, Racism, and Anti-Racism in NLP" ACL (2021). (<a class="link" href="https://aclanthology.org/2021.acl-long.149.pdf" target="_blank">text</a>) </div></li>
        </li>
        </ul>

        <br>
        <br>
        These categories are not independent: if we want NLP to be for "social good", it needs to be ethical. If we want to identify and mitigate "bias"
        in our models, we need social science perspectives on what "bias" is. 
        For a more formal overview, including how these concepts fit together and high-level goals, you can also take a look at my recent <a  href="docs/2021_Research_CS_4page.pdf">research statement</a>.

        <br>
        <br>
        <div class="subtitle">Methods and Data</div>
        Most of my research focuses on identifying abstract concepts in text, e.g. "bias", "propaganda", that can be subtle and implicit.
        This type of content is difficult to identify using established methods or supervised approaches, and projects typically
        involve developing new frameworks that incorporate relevant context. Some of the common challenges include accounting for confounding variables, reducing the need
        for hand-annotated data, and handling domain-specific concepts and terminology.
        Sometimes this involves deep-learning, sometimes it involves counting word frequencies, and sometimes it involves manual analysis.
        <br>
        <br>
        Additionally, most of my work involves exploring new data that is digitized, but can be messy and unstructured (newspaper articles, social media, social workers' notes).
        A lot of projects have started with a great data set, where we need to figure out how to process it and what to do with it.
        If you're most excited about building complex models and don't want
        to deal with data wrangling, we're probably not a great match.

        While I most commonly work with text data, some of my recent projects have focused on speech.
        
        <br>
        <br>
        <div class="subtitle">Expected Background</div>
        I am primarily looking for students who are highly motivated to work on social issues.
        Students from interdisciplinary backgrounds are welcome.
        I have had lots of very productive collaborations with people in a variety of fields and institutions, including political science, economics, statistics, etc.
        While I do not expect incoming students to have extensive experience in NLP, students should be comfortable writing code.
        <br>
        <br>
        <div class="subtitle">Lab Culture and Values</div>
        I will strive to maintain a lab that values inclusiveness and is a safe environment for all members. As a new professor, I expect
        to work closely with students, including regular meetings (e.g. weekly) and active involvement in projects, such as helping with
        paper writing. 
        Students who are looking for hands-on involvement and close collaboration are a good fit;
        students who would prefer to operate independently with infrequent meetings are not.
        While I do expect frequent communication, I have no intention of tracking students' work hours or vacation time, and students will be encouraged to set schedules
        that best support their mental health and productivity.
     
      </div>

  </div>

<!--   <div style="margin-top: 10px; text-align: center; font-size: 14px;"> -->
<!--   Last Updated: October 11, 2018 -->
<!--   </div> -->

</body>
</html>
